{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccd92c6",
   "metadata": {},
   "source": [
    "\n",
    "# Face Mask Detection: End-to-End Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline for building a Face Mask Detection system.\n",
    "We will cover:\n",
    "1. **Data Loading & Exploration**: Understanding our dataset.\n",
    "2. **Preprocessing**: Preparing images for the model.\n",
    "3. **Model Architecture**: Using Transfer Learning with ResNet50.\n",
    "4. **Training**: Implementing the training loop with metrics.\n",
    "5. **Evaluation**: Analyzing model performance.\n",
    "6. **Inference**: Making predictions on new images.\n",
    "\n",
    "**Train of Thought**:\n",
    "Throughout this notebook, I will explain the reasoning behind key decisions, such as why we chose specific hyperparameters, loss functions, and model architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path so we can import our modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from dataset import create_data_loaders, get_transforms\n",
    "from model import create_model\n",
    "from train import Trainer\n",
    "from inference import FaceMaskPredictor\n",
    "from utils import plot_training_history\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a165c7",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Loading & Exploration\n",
    "\n",
    "First, we need to load our dataset. We assume the data is organized in folders representing classes.\n",
    "We use `create_data_loaders` from our `src.dataset` module which handles splitting the data into training and validation sets.\n",
    "\n",
    "**Why split data?**\n",
    "It's crucial to keep a separate validation set to monitor for overfitting. If the model performs well on training data but poorly on validation data, it's memorizing instead of learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "DATA_DIR = '../data/raw'  # Adjust if your data is elsewhere\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # Set to 0 for Windows compatibility in notebooks sometimes\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, class_to_idx = create_data_loaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"Classes: {class_to_idx}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86933e1a",
   "metadata": {},
   "source": [
    "\n",
    "### Visualizing Samples\n",
    "\n",
    "Let's look at some images from our data loader to verify they are loaded correctly and see what the transforms look like.\n",
    "We apply normalization for training, so we need to denormalize for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # Denormalize\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[:4])\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "titles = [idx_to_class[x.item()] for x in classes[:4]]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "imshow(out, title=titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848f660",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Model Architecture\n",
    "\n",
    "We use **ResNet50** as our backbone.\n",
    "\n",
    "**Why ResNet50?**\n",
    "1.  **Transfer Learning**: It's pre-trained on ImageNet, meaning it already knows how to extract features (edges, textures, shapes). We only need to fine-tune it for masks.\n",
    "2.  **Performance**: It offers a good balance between accuracy and computational cost.\n",
    "3.  **Residual Connections**: Solves the vanishing gradient problem, allowing for deeper networks.\n",
    "\n",
    "We replace the final fully connected layer to output our 3 classes: `with_mask`, `without_mask`, `mask_weared_incorrect`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(model_name='resnet50', num_classes=len(class_to_idx), pretrained=True)\n",
    "model = model.to(DEVICE)\n",
    "print(\"Model created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ca706",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Training\n",
    "\n",
    "We use the `Trainer` class from `src.train`.\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **Loss Function**: `CrossEntropyLoss` (standard for multi-class classification).\n",
    "- **Optimizer**: `Adam` (adaptive learning rates, generally converges faster than SGD).\n",
    "- **Learning Rate**: `1e-3` (good starting point for Adam).\n",
    "- **Scheduler**: `ReduceLROnPlateau` (lowers LR if validation loss stops improving).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Setup training components\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# Config for trainer\n",
    "config = {\n",
    "    'model_name': 'resnet50',\n",
    "    'epochs': 5,  # Reduced for demonstration\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': 0.001,\n",
    "    'checkpoint_dir': '../models/checkpoints_notebook',\n",
    "    'results_dir': '../results/notebook_metrics',\n",
    "    'save_frequency': 1,\n",
    "    'patience': 3\n",
    "}\n",
    "\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "os.makedirs(config['results_dir'], exist_ok=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    class_to_idx=class_to_idx,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280211a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run training\n",
    "# Note: This might take a while depending on your hardware.\n",
    "# If you want to skip training, you can load the pre-trained model in the next section.\n",
    "history = trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a59778",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Evaluation\n",
    "\n",
    "Let's inspect the training history and evaluate the model on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d56d9c",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Inference\n",
    "\n",
    "Now we can use our trained model to make predictions on new images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load best model\n",
    "# If training was skipped, point this to the pre-trained model\n",
    "best_model_path = os.path.join(config['checkpoint_dir'], 'best_model.pth')\n",
    "if not os.path.exists(best_model_path):\n",
    "    print(\"Notebook checkpoint not found, trying main checkpoints...\")\n",
    "    best_model_path = '../models/checkpoints/best_model.pth'\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"Loading model from {best_model_path}\")\n",
    "    predictor = FaceMaskPredictor(model_path=best_model_path, device=DEVICE)\n",
    "\n",
    "    # Pick a random image from validation set to test\n",
    "    import random\n",
    "    val_dataset = val_loader.dataset\n",
    "    rand_idx = random.randint(0, len(val_dataset)-1)\n",
    "    \n",
    "    # We need to access the original image path. \n",
    "    # FaceMaskDataset stores samples as a list of dicts with 'image_path'\n",
    "    sample = val_dataset.samples[rand_idx]\n",
    "    img_path = sample['image_path']\n",
    "    print(f\"Testing on: {img_path}\")\n",
    "\n",
    "    predictor.visualize_prediction(img_path)\n",
    "else:\n",
    "    print(\"No model checkpoint found. Please train the model or provide a checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255dd2",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "We have successfully built a face mask detection system.\n",
    "- **Preprocessing**: Resized to 224x224, normalized.\n",
    "- **Model**: ResNet50 achieved good accuracy.\n",
    "- **Next Steps**: Deploy this model using a web framework like Flask or Streamlit, or integrate it into a video stream.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
